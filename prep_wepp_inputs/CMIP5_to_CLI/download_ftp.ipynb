{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to gdo-dcp.ucllnl.org...\n",
      "Downloading files from /pub/dcp/subset/202112011100Nr5d_n_DtgiWu...\n",
      "0TAG:ST1_BCCA\n",
      "202112011100Nr5d_n_DtgiWu.txt\n",
      "Notes.txt\n",
      "Projections5.txt\n",
      "Extraction_pr.nc\n",
      "Extraction_tasmax.nc\n",
      "Extraction_tasmin.nc\n",
      "MetaData.txt\n",
      "Notes.txt\n",
      "Projections5.txt\n",
      "bcca5.tar.gz\n",
      "Download complete.\n"
     ]
    }
   ],
   "source": [
    "def run_ftp_download(ID, output_path):\n",
    "    \"\"\"\n",
    "    Function for downloading subset request results submitted through the \n",
    "    Green Data Oasis: Downscaled Climate and Hydrology Projections website \n",
    "    (https://gdo-dcp.ucllnl.org/downscaled_cmip_projections/).\n",
    "    Uses native Python 3 libraries. No external dependencies are required.\n",
    "\n",
    "    Please provide bug notifications via this form:\n",
    "    https://gdo-dcp.ucllnl.org/downscaled_cmip_projections/dcpInterface.html#Feedback\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s_job_id: string\n",
    "        Job identifier provided in DCP notification email (sent from no-reply@gdo4.llnl.gov).\n",
    "        This is the directory on the FTP the data are located within.\n",
    "    s_local_destination: string\n",
    "        Destination location for the files to be downloaded to on the local machine.\n",
    "        Default is the current working directory (i.e. os.getcwd()).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Path on the local machine where the downloaded files are located.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Bash terminal example:\n",
    "        python ./ftp_download.py <s_job_id> [s_local_destination]\n",
    "        python ./ftp_download.py 202102031234Nl3m_a_J8R3kl DCP_SubsetResults\n",
    "\n",
    "    PowerShell terminal example:\n",
    "        python .\\ftp_download.py <s_job_id> [s_local_destination]\n",
    "        python .\\ftp_download.py 202102031234Nl3m_a_J8R3kl DCP_SubsetResults\n",
    "\n",
    "    Python script example:\n",
    "        from ftp_download import download_dcp_subset_results\n",
    "        pth_out = download_dcp_subset_results('202102031234Nl3m_a_J8R3kl', \n",
    "                                              'DCP_SubsetResults')\n",
    "    \"\"\"\n",
    "\n",
    "    import ftplib\n",
    "    import os\n",
    "    import time\n",
    "    import sys\n",
    "    import getopt\n",
    "    import re\n",
    "\n",
    "    def download_dcp_subset_results(s_job_id, s_local_destination=None):\n",
    "        \"\"\"\n",
    "        Download subset request results submitted through the Green Data Oasis:\n",
    "        Downscaled Climate and Hydrology Projections website \n",
    "        (https://gdo-dcp.ucllnl.org/downscaled_cmip_projections/). Requires \n",
    "        the job identifier from the email notification that the request was completed. \n",
    "        Wraps _download_files.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        s_job_id: str\n",
    "            Job identifier provided in DCP notification email.\n",
    "            This is the directory on the FTP the data are located within.\n",
    "        s_local_destination: str\n",
    "            Destination location for the files to be downloaded to on the local machine\n",
    "            Default is the current working directory (i.e. os.getcwd())\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Path on the local machine where files are located\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        from ftp_download import download_dcp_subset_results\n",
    "        pth = download_dcp_subset_results('202102031234Nl3m_a_J8R3kl', \n",
    "                                          'DCP_SubsetResults')\n",
    "        \"\"\"\n",
    "\n",
    "        ### Pre-Processing ###\n",
    "        # Convert local path to abs path\n",
    "        # Perform a few checks\n",
    "        s_local_destination = _build_dest_path(s_local_destination)\n",
    "\n",
    "        # Remove \".job\" if passed in job identifier\n",
    "        s_job_id = s_job_id.rstrip('.job')\n",
    "\n",
    "        # Check that user-supplied job identifier is reasonable\n",
    "        if not _check_job_id(s_job_id):\n",
    "            raise ValueError('Job identifier %s is invalid.' % s_job_id)\n",
    "\n",
    "        # Create full file path to ftp\n",
    "        s_input_path = _build_ftp_path(s_job_id)\n",
    "\n",
    "        # Login to the FTP site\n",
    "        s_server_address = \"gdo-dcp.ucllnl.org\"\n",
    "        ftp = ftplib.FTP(s_server_address)\n",
    "        ftp.login()\n",
    "        print('Connected to %s...' % s_server_address)\n",
    "\n",
    "        # Start download\n",
    "        print('Downloading files from %s...' % s_input_path)\n",
    "        _ = _download_files(ftp, s_input_path, s_local_destination)\n",
    "\n",
    "        # Close connection\n",
    "        ftp.quit()\n",
    "\n",
    "        # Notify of completion\n",
    "        print('Download complete.')\n",
    "\n",
    "        # Get full file path to where data was downloaded to\n",
    "        pth = os.path.join(s_local_destination, *s_input_path.split('/')[1:])\n",
    "        pth = os.path.normpath(pth)\n",
    "\n",
    "        return(pth)\n",
    "\n",
    "\n",
    "    def _download_files(ftp, s_input_path, s_destination_path, b_change_dir=False):\n",
    "        \"\"\"\n",
    "        Worker function to download the DCP directory recursively\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ftp: ftplib.FTP\n",
    "            An ftp connection to the server\n",
    "        s_input_path: str\n",
    "            Location of the folder on the server without the server name\n",
    "        s_destination_path: str\n",
    "            Destination location for the files to be downloaded to on the local machine\n",
    "        b_change_dir: bool\n",
    "            Indicates if the worker should move up a directory at the end of the process.\n",
    "            Default is False.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None. All files are downloaded to the local machine.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        ### Create the path on the local machine ###\n",
    "        # Separate out the remote path\n",
    "        sl_split = s_input_path.split('/')[1:]\n",
    "\n",
    "        # Make the paths recursively on the local host\n",
    "        s_path = s_destination_path\n",
    "        for s_directory in sl_split:\n",
    "            # Join the current path with the next proposed step\n",
    "            s_path = os.path.join(s_path, s_directory)\n",
    "\n",
    "            # Test if the file already exists or is a file\n",
    "            if not os.path.isdir(s_path) and '.' not in s_path:\n",
    "                os.mkdir(s_path)\n",
    "\n",
    "        ### Begin the download from the remote site ###\n",
    "        # Change to the destination on local machine\n",
    "        os.chdir(s_destination_path)\n",
    "\n",
    "        # Navigate to subset results directory\n",
    "        ftp.cwd(s_input_path)\n",
    "\n",
    "        # Get the contents of the results directory\n",
    "        sl_filelist = ftp.nlst()\n",
    "\n",
    "        # Loop over each entry at the results directory\n",
    "        for s_file in sl_filelist:\n",
    "            # Pause momentarily to allow communication\n",
    "            time.sleep(0.05)\n",
    "\n",
    "            # Parse the directory entry\n",
    "            try:\n",
    "                # Attempt to download the file\n",
    "                o_file = open(os.path.join(s_path, s_file), \"wb\")\n",
    "                ftp.retrbinary(\"RETR \" + s_file, o_file.write)\n",
    "                print('%s' % s_file)\n",
    "                o_file.close()\n",
    "\n",
    "            except:\n",
    "                # Download attempt failed. It must be a directory.\n",
    "                # Delete the initial file attempt\n",
    "                o_file.close()\n",
    "                os.remove(os.path.join(s_path, s_file))\n",
    "\n",
    "                # Recursive call into the directory\n",
    "                _ = _download_files(ftp, s_input_path + '/' + s_file,\n",
    "                                    s_destination_path, True)\n",
    "\n",
    "        # Move up one directory to keep the workers in sync\n",
    "        if b_change_dir:\n",
    "            ftp.cwd(\"..\")\n",
    "\n",
    "        return(None)\n",
    "\n",
    "\n",
    "    def _check_job_id(s_job_id):\n",
    "        '''\n",
    "        Cursory verification of user-supplied job identifier\n",
    "        '''\n",
    "        pat = re.compile('20[0-9]{10}.+_[a-zA-Z0-9_]{6}$')\n",
    "        return(pat.match(s_job_id))\n",
    "\n",
    "\n",
    "    def _build_dest_path(pth):\n",
    "        '''\n",
    "        Build destination path on local machine and a few checks\n",
    "        '''\n",
    "        if pth:\n",
    "            # Convert to abs path if not already\n",
    "            pth = os.path.abspath(pth)\n",
    "\n",
    "            # Check that destination path exists\n",
    "            if not os.path.exists(pth):\n",
    "                raise IOError('%s path does not exist.' % pth)\n",
    "\n",
    "            # Check that destination path is a directory\n",
    "            if not os.path.isdir(pth):\n",
    "                raise IOError('%s exists but is not a directory.' % pth)\n",
    "\n",
    "        else:\n",
    "            # Set to current working directory\n",
    "            pth = os.getcwd()\n",
    "\n",
    "        return(pth)\n",
    "\n",
    "\n",
    "    def _build_ftp_path(s_job_id, s_base_path=\"/pub/dcp/subset\"):\n",
    "        '''\n",
    "        Build ftp file path\n",
    "        '''\n",
    "        # Combine job identifier with ftp path\n",
    "        pth = os.path.join(s_base_path, s_job_id)\n",
    "\n",
    "        # Clean path\n",
    "        pth = os.path.normpath(pth)\n",
    "\n",
    "        # Change to forward slash for ftp\n",
    "        pth = pth.replace(os.sep, '/')\n",
    "\n",
    "        return(pth)\n",
    "\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "\n",
    "        # Parse inputs\n",
    "        args = sys.argv[1:]\n",
    "        if len(args) == 1:\n",
    "            s_job_id = args[0]\n",
    "            s_local_destination = None\n",
    "        elif len(args) == 2:\n",
    "            s_job_id = args[0]\n",
    "            s_local_destination = args[1]\n",
    "        else:\n",
    "            sys.stderr.write('Expected 1 or 2 arguments, received %i' % len(args))\n",
    "            sys.exit(1)\n",
    "\n",
    "        #############################################################################\n",
    "        # Call the download processor\n",
    "        download_dcp_subset_results(ID, output_path)\n",
    "        \n",
    "run_ftp_download('202112011100Nr5d_n_DtgiWu', 'C:\\\\Users\\\\Garner\\\\Soil_Erosion_Project\\\\WEPP_PRWs\\\\ST1\\\\netCDF\\\\BCCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
